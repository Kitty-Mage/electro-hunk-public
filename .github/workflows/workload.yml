name: Dynamic Heavy Load Simulation ON UBUNTUUUUU

on:
  push:
    branches: ["main"]

jobs:
  heavy-computation:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Ensure required tools (column, iostat) are installed
        run: |
          sudo apt-get update
          # Install sysstat for iostat, and column from bsdmainutils or util-linux
          sudo apt-get install -y sysstat || echo "sysstat not available"
          sudo apt-get install -y bsdmainutils || sudo apt-get install -y util-linux

      - name: Print system metrics and add to summary
        run: |
          echo "### ðŸ–¥ï¸ System Information" >> system_info.md
          echo "**Date:** $(date)" >> system_info.md
          echo "**OS:** $(uname -a)" >> system_info.md
          echo "**CPU cores:** $(nproc)" >> system_info.md
          echo "**Total RAM:** $(free -h | awk '/^Mem:/ {print $2}')" >> system_info.md
          echo "**Disk Space (/):** $(df -h / | awk 'NR==2 {print $2 " total, " $4 " free"}')" >> system_info.md
          echo "**Uptime:** $(uptime -p)" >> system_info.md

          echo "" >> system_info.md
          echo "### ðŸ’½ Disk I/O (1s sample)" >> system_info.md
          sudo apt-get update && sudo apt-get install -y sysstat >/dev/null 2>&1
          iostat_output=$(iostat -dx 1 2 | tail -n +7 | awk 'NF && $1 != "Device:" {print $1, "r/s:", $4, "w/s:", $5}' | column -t)
          echo '```' >> system_info.md
          echo "$iostat_output" >> system_info.md
          echo '```' >> system_info.md

          echo "" >> system_info.md
          echo "### ðŸŒ Network I/O (RX/TX bytes per interface)" >> system_info.md
          rx_tx=$(cat /proc/net/dev | awk 'NR>2 {print $1, "RX:", $2, "TX:", $10}' | column -t)
          echo '```' >> system_info.md
          echo "$rx_tx" >> system_info.md
          echo '```' >> system_info.md

          echo "" >> system_info.md
          echo "### ðŸ“ˆ Load Average" >> system_info.md
          echo "$(uptime | awk -F'load average:' '{print $2}')" >> system_info.md

          cat system_info.md >> $GITHUB_STEP_SUMMARY

      - name: Start timer
        run: echo "START_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Simulate heavy computation
        run: |
          echo "Starting heavy computation..."

          echo "Running single-threaded tests..."
          for i in {1..15}; do
            echo "Running iteration $i"
            openssl rand -base64 50000000 | gzip -9 > /dev/null
          done

          echo "Running multi-threaded tests..."
          for j in {1..3}; do
            echo "Running parallel batch $j"
            openssl rand -base64 40000000 | gzip -9 > /dev/null &
            for k in {1..10}; do openssl dgst -sha512 <(openssl rand -base64 20000000) > /dev/null; done &
            cat /dev/urandom | head -c 100M | md5sum &
            seq 1 100000000 | wc &
            wait
          done

      - name: Simulate heavy disk I/O
        run: |
          pwd
          ls -l 
          echo "Starting heavy disk I/O..."

          dd if=/dev/zero of=largefile bs=1M count=4096
          sync

          echo "Performing random read operations..."
          for i in {1..3}; do
            dd if=largefile of=/dev/null bs=8k skip=$RANDOM count=100000 iflag=direct
          done

          echo "Performing parallel read/write operations..."
          for i in {1..3}; do
            dd if=/dev/zero of=largefile2 bs=1M count=2048 conv=fsync &
            dd if=largefile of=/dev/null bs=1M count=2048 &
            wait
          done

          rm largefile largefile2

      - name: Simulate heavy network I/O
        run: |
          echo "Starting heavy network I/O..."

          dd if=/dev/urandom of=upload_test.bin bs=1M count=100

          echo "Running parallel downloads from multiple sources..."
          for j in {1..3}; do
            echo "Download batch $j"
            curl -s --insecure --max-time 300 https://speed.hetzner.de/1GB.bin > /dev/null &
            curl -s --insecure --max-time 300 https://bodo.com/10GB.bin > /dev/null &
            curl -s --insecure --max-time 300 https://speedtest.tele2.net/100MB.zip > /dev/null &
            for i in {1..20}; do
              curl -s --insecure https://www.example.org/ > /dev/null &
            done
            wait
          done

          echo "Testing upload performance..."
          for k in {1..5}; do
            curl -s --insecure -X POST -F "file=@upload_test.bin" https://httpbin.org/post > /dev/null
          done

          echo "Testing multiple concurrent connections..."
          for m in {1..3}; do
            for n in {1..20}; do
              curl -s --insecure https://raw.githubusercontent.com/curl/curl/master/README > /dev/null &
            done
            wait
          done

          rm upload_test.bin

      - name: End timer
        run: |
          END_TIME=$(date +%s)
          START_TIME=${{ env.START_TIME }}
          DURATION=$((END_TIME - START_TIME))
          echo "Workflow Duration: $DURATION seconds"
          echo "**â±ï¸ Workflow Duration:** $DURATION seconds" >> $GITHUB_STEP_SUMMARY

      - name: Store duration as artifact
        run: echo "${{ env.START_TIME }},$(date +%s)" > workflow_duration.csv

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: workflow-timing
          path: workflow_duration.csv

  heavy-computation-v2:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Ensure required tools (column, iostat) are installed
        run: |
          sudo apt-get update
          # Install sysstat for iostat, and column from bsdmainutils or util-linux
          sudo apt-get install -y sysstat || echo "sysstat not available"
          sudo apt-get install -y bsdmainutils || sudo apt-get install -y util-linux

      - name: Print system metrics and add to summary
        run: |
          echo "### ðŸ–¥ï¸ System Information" >> system_info.md
          echo "**Date:** $(date)" >> system_info.md
          echo "**OS:** $(uname -a)" >> system_info.md
          echo "**CPU cores:** $(nproc)" >> system_info.md
          echo "**Total RAM:** $(free -h | awk '/^Mem:/ {print $2}')" >> system_info.md
          echo "**Disk Space (/):** $(df -h / | awk 'NR==2 {print $2 " total, " $4 " free"}')" >> system_info.md
          echo "**Uptime:** $(uptime -p)" >> system_info.md

          echo "" >> system_info.md
          echo "### ðŸ’½ Disk I/O (1s sample)" >> system_info.md
          sudo apt-get update && sudo apt-get install -y sysstat >/dev/null 2>&1
          iostat_output=$(iostat -dx 1 2 | tail -n +7 | awk 'NF && $1 != "Device:" {print $1, "r/s:", $4, "w/s:", $5}' | column -t)
          echo '```' >> system_info.md
          echo "$iostat_output" >> system_info.md
          echo '```' >> system_info.md

          echo "" >> system_info.md
          echo "### ðŸŒ Network I/O (RX/TX bytes per interface)" >> system_info.md
          rx_tx=$(cat /proc/net/dev | awk 'NR>2 {print $1, "RX:", $2, "TX:", $10}' | column -t)
          echo '```' >> system_info.md
          echo "$rx_tx" >> system_info.md
          echo '```' >> system_info.md

          echo "" >> system_info.md
          echo "### ðŸ“ˆ Load Average" >> system_info.md
          echo "$(uptime | awk -F'load average:' '{print $2}')" >> system_info.md

          cat system_info.md >> $GITHUB_STEP_SUMMARY

      - name: Start timer
        run: echo "START_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Simulate heavy computation
        run: |
          echo "Starting heavy computation..."

          echo "Running single-threaded tests..."
          for i in {1..15}; do
            echo "Running iteration $i"
            openssl rand -base64 50000000 | gzip -9 > /dev/null
          done

          echo "Running multi-threaded tests..."
          for j in {1..3}; do
            echo "Running parallel batch $j"
            openssl rand -base64 40000000 | gzip -9 > /dev/null &
            for k in {1..10}; do openssl dgst -sha512 <(openssl rand -base64 20000000) > /dev/null; done &
            cat /dev/urandom | head -c 100M | md5sum &
            seq 1 100000000 | wc &
            wait
          done

      - name: Simulate heavy disk I/O
        run: |
          pwd
          ls -l 
          echo "Starting heavy disk I/O..."

          dd if=/dev/zero of=largefile bs=1M count=4096
          sync

          echo "Performing random read operations..."
          for i in {1..3}; do
            dd if=largefile of=/dev/null bs=8k skip=$RANDOM count=100000 iflag=direct
          done

          echo "Performing parallel read/write operations..."
          for i in {1..3}; do
            dd if=/dev/zero of=largefile2 bs=1M count=2048 conv=fsync &
            dd if=largefile of=/dev/null bs=1M count=2048 &
            wait
          done

          rm largefile largefile2

      - name: Simulate heavy network I/O
        run: |
          echo "Starting heavy network I/O..."

          dd if=/dev/urandom of=upload_test.bin bs=1M count=100

          echo "Running parallel downloads from multiple sources..."
          for j in {1..3}; do
            echo "Download batch $j"
            curl -s --insecure --max-time 300 https://speed.hetzner.de/1GB.bin > /dev/null &
            curl -s --insecure --max-time 300 https://bodo.com/10GB.bin > /dev/null &
            curl -s --insecure --max-time 300 https://speedtest.tele2.net/100MB.zip > /dev/null &
            for i in {1..20}; do
              curl -s --insecure https://www.example.org/ > /dev/null &
            done
            wait
          done

          echo "Testing upload performance..."
          for k in {1..5}; do
            curl -s --insecure -X POST -F "file=@upload_test.bin" https://httpbin.org/post > /dev/null
          done

          echo "Testing multiple concurrent connections..."
          for m in {1..3}; do
            for n in {1..20}; do
              curl -s --insecure https://raw.githubusercontent.com/curl/curl/master/README > /dev/null &
            done
            wait
          done

          rm upload_test.bin

      - name: End timer
        run: |
          END_TIME=$(date +%s)
          START_TIME=${{ env.START_TIME }}
          DURATION=$((END_TIME - START_TIME))
          echo "Workflow Duration: $DURATION seconds"
          echo "**â±ï¸ Workflow Duration:** $DURATION seconds" >> $GITHUB_STEP_SUMMARY

      - name: Store duration as artifact
        run: echo "${{ env.START_TIME }},$(date +%s)" > workflow_duration.csv

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: workflow-timing-v2
          path: workflow_duration-v2.csv
